{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images\\Logo_UCLL_ENG_RGB.png\" style=\"background-color:white;\" />\n",
    "\n",
    "# Data Analytics & Machine learning\n",
    "\n",
    "Lecturers: Aimée Lynn Backiel, Kenric Borgelioen, Sofie Torfs, Lies Bollens\n",
    "\n",
    "Academic year 2025-2026\n",
    "\n",
    "## Lab 8: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture outline\n",
    "\n",
    "1. One large exercise covering all we have done so far in this course applied to classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap of last lecture(s)\n",
    "\n",
    "#### Lab 1\n",
    "\n",
    "1. We ensured we had a valid Python installation.\n",
    "2. We learnt what a virtual environment is:\n",
    "   * Isolated Python executable and packages.\n",
    "   * We created a virtual environment.\n",
    "3. Absolute path vs relative path recap.\n",
    "4. Recap of data structures in Python\n",
    "\n",
    "#### Lab 2\n",
    "1. Installed Pandas\n",
    "2. Learnt how to read data\n",
    "3. Learnt how to calculate mean, mode, median etc.\n",
    "4. Basic exploration of the 4 variables\n",
    "\n",
    "#### Lab 3\n",
    "1. Wrapped up computing summary statistics (mean, median, mode, ...)\n",
    "2. Learnt how to deal with outliers \n",
    "3. Focused on exploration of data\n",
    "\n",
    "#### Lab 4\n",
    "1. Univariate data visualization using Matplotlib\n",
    "   1. Figures and axes\n",
    "   2. Histograms\n",
    "   3. Box plots\n",
    "   4. Bar charts\n",
    "2. Multivariate data visualization using Seaborn\n",
    "   1. Scatter plots\n",
    "   2. Small multiples\n",
    "   3. Color coding\n",
    "\n",
    "#### Lab 5\n",
    "1. Intro to machine learning using scikit-learn\n",
    "   1. Preprocessing\n",
    "      1. One Hot encoding\n",
    "      2. Scaling\n",
    "      3. Outliers\n",
    "   2. Regression\n",
    "\n",
    "#### Lab 6\n",
    "1. Preprocessing with scikit-learn\n",
    "   1. ColumnTransformer: Apply a transformation to specific columns.\n",
    "   2. Pipeline: Do several transformations after each other\n",
    "2. Evaluation:\n",
    "   1. Why the mean of the error is a bad idea\n",
    "   2. Mean absolute error\n",
    "   3. Mean squared error\n",
    "\n",
    "### Lab 7\n",
    "1. Feature engineering\n",
    "   1. Binning\n",
    "   2. Interactions\n",
    "   3. Custom features\n",
    "2. Rounding up model evaluation\n",
    "   1. Cross validation\n",
    "   2. Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our next case: Hotel booking dataset\n",
    "\n",
    "source: https://www.sciencedirect.com/science/article/pii/S2352340918315191\n",
    "\n",
    "*This data article describes two datasets with hotel demand data. One of the hotels (H1) is a resort hotel and the other is a city hotel (H2). Both datasets share the same structure, with 31 variables describing the 40,060 observations of H1 and 79,330 observations of H2. Each observation represents a hotel booking. Both datasets comprehend bookings due to arrive between the 1st of July of 2015 and the 31st of August 2017, including bookings that effectively arrived and bookings that were canceled. Both hotels are located in Portugal: H1 at the resort region of Algarve and H2 at the city of Lisbon.*\n",
    "\n",
    "The goal is to help the two hotels maximize their revenue.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|variable                       |class     |description |\n",
    "|:------------------------------|:---------|:-----------|\n",
    "|hotel                          |character | Hotel (H1 = Resort Hotel or H2 = City Hotel) |\n",
    "|is_canceled                    |double    | Value indicating if the booking was canceled (1) or not (0) |\n",
    "|lead_time                      |double    | Number of days that elapsed between the entering date of the booking into the PMS and the arrival date |\n",
    "|arrival_date_year              |double    | Year of arrival date|\n",
    "|arrival_date_month             |character | Month of arrival date|\n",
    "|arrival_date_week_number       |double    | Week number of year for arrival date|\n",
    "|arrival_date_day_of_month      |double    | Day of arrival date|\n",
    "|stays_in_weekend_nights        |double    | Number of weekend nights (Saturday or Sunday) the guest stayed or booked to stay at the hotel |\n",
    "|stays_in_week_nights           |double    |  Number of week nights (Monday to Friday) the guest stayed or booked to stay at the hotel|\n",
    "|adults                         |double    | Number of adults|\n",
    "|children                       |double    | Number of children|\n",
    "|babies                         |double    |Number of babies |\n",
    "|meal                           |character | Type of meal booked. Categories are presented in standard hospitality meal packages: <br> Undefined/SC – no meal package;<br>BB – Bed & Breakfast; <br> HB – Half board (breakfast and one other meal – usually dinner); <br> FB – Full board (breakfast, lunch and dinner) |\n",
    "|country                        |character | Country of origin. Categories are represented in the ISO 3155–3:2013 format |\n",
    "|market_segment                 |character | Market segment designation. In categories, the term “TA” means “Travel Agents” and “TO” means “Tour Operators” |\n",
    "|distribution_channel           |character | Booking distribution channel. The term “TA” means “Travel Agents” and “TO” means “Tour Operators” |\n",
    "|is_repeated_guest              |double    | Value indicating if the booking name was from a repeated guest (1) or not (0) |\n",
    "|previous_cancellations         |double    | Number of previous bookings that were cancelled by the customer prior to the current booking |\n",
    "|previous_bookings_not_canceled |double    | Number of previous bookings not cancelled by the customer prior to the current booking |\n",
    "|reserved_room_type             |character | Code of room type reserved. Code is presented instead of designation for anonymity reasons |\n",
    "|assigned_room_type             |character | Code for the type of room assigned to the booking. Sometimes the assigned room type differs from the reserved room type due to hotel operation reasons (e.g. overbooking) or by customer request. Code is presented instead of designation for anonymity reasons |\n",
    "|booking_changes                |double    | Number of changes/amendments made to the booking from the moment the booking was entered on the PMS until the moment of check-in or cancellation|\n",
    "|deposit_type                   |character | Indication on if the customer made a deposit to guarantee the booking. This variable can assume three categories:<br>No Deposit – no deposit was made;<br>Non Refund – a deposit was made in the value of the total stay cost;<br>Refundable – a deposit was made with a value under the total cost of stay. |\n",
    "|agent                          |character | ID of the travel agency that made the booking |\n",
    "|company                        |character | ID of the company/entity that made the booking or responsible for paying the booking. ID is presented instead of designation for anonymity reasons |\n",
    "|days_in_waiting_list           |double    | Number of days the booking was in the waiting list before it was confirmed to the customer |\n",
    "|customer_type                  |character | Type of booking, assuming one of four categories:<br>Contract - when the booking has an allotment or other type of contract associated to it;<br>Group – when the booking is associated to a group;<br>Transient – when the booking is not part of a group or contract, and is not associated to other transient booking;<br>Transient-party – when the booking is transient, but is associated to at least other transient booking|\n",
    "|adr                            |double    | Average Daily Rate as defined by dividing the sum of all lodging transactions by the total number of staying nights |\n",
    "|required_car_parking_spaces    |double    | Number of car parking spaces required by the customer |\n",
    "|total_of_special_requests      |double    | Number of special requests made by the customer (e.g. twin bed or high floor)|\n",
    "|reservation_status             |character | Reservation last status, assuming one of three categories:<br>Canceled – booking was canceled by the customer;<br>Check-Out – customer has checked in but already departed;<br>No-Show – customer did not check-in and did inform the hotel of the reason why |\n",
    "|reservation_status_date        |double    | Date at which the last status was set. This variable can be used in conjunction with the ReservationStatus to understand when was the booking canceled or when did the customer checked-out of the hotel|\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ❓ Go back to lab 2. Read in the H1 and H2 dataset. What was the very first step when working with a dataset? Execute that one. Make sure the necessary packages are installed and imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ❓ The next thing we need to decide on, is what we want to do with this dataset. We have many different variables and thus things we can do. What would you do with this dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of multiple things to do with this set:\n",
    "1. Finding out who cancels reservations (classifcation)\n",
    "2. Finding groups in the customers (clustering)\n",
    "3. Predicting the amount of rooms to be booked on a given day (regression)\n",
    "4. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will focus in this lab on finding out who cancels their reservation. This means we will be **predicting a categorical value**. `isCanceled` is a number but in our dataset it should be regarded as a discrete category. This is called **classification**. When doing classification we will need slightly different machine learning models but most importantly, we will need different evaluation metrics. The full details are discussed in the theory sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still start of by doing exploring the dataset using Pandas exclusively and move on to some plots later on. The choice of which tool to use is yours. Start by combining both dataset in to one set called 'hotel_df'. Make sure to indicate which data is coming from which hotel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ❓ First, take a general look at the data. Are there any missing values? Are there any values that do not make sense. Make sure to handle these missing values appropriatly. Then formulate and anwser at least 3 business questions that you think are interesting. Focus on one variable at the time. Use plots as well as metrics to study these variables.\n",
    "An example of a possible business question might be: \"Which countries are our guests coming from?\". In a later stage, you could look at the relationship between country of origin and the cancellations. Create your own code and markdown cells. Make sure to explain/document everything you do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ❓ Now, move on to a bivariate or multivariate analysis: looking at the relationship between two or more of the variables at the same time. Again, start by formulating questions and answer them. Keep in mind that we want to figure out why people cancel their holidays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ❓ Finally, let's check which variables are highly correlated with cancellations\n",
    "(hint use numeric_only=True when making the correlations, that way you don't have to type out all numeric columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ❓Go back to lab 5 and 6 and take another look on how to prepare your data for modeling. The same steps are needed for classification as for regression. Take the necessary steps below. Make your own code and markdown cells.\n",
    "We suggest calling your final prepocessor 'preprocessor' so the code below still works. Otherwise, you will have to update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ❓Below, we have added some code that allows you to study the correlation of the variables after preprocessing. Take a look, what changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Fit the preprocessor on your training data\n",
    "preprocessor.fit(X_train)\n",
    "\n",
    "# 2. Transform the data\n",
    "X_processed = preprocessor.transform(X_train)\n",
    "\n",
    "# 3. Convert to a DataFrame\n",
    "#    If your preprocessor includes ColumnTransformer with named columns, you can get feature names\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "X_processed_df = pd.DataFrame(X_processed, columns=feature_names)\n",
    "# Add IsCancelled back\n",
    "X_processed_df[\"IsCanceled\"] = y_train.values\n",
    "\n",
    "# 4. Compute the correlation matrix\n",
    "corr_matrix = X_processed_df.corr()\n",
    "\n",
    "# 5. (Optional) visualize or inspect correlations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Correlation Matrix after Preprocessing\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(X_processed_df.corr(numeric_only=True)['IsCanceled']).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ❓Take a look at the lecture slides. Which classification models have we seen in class? In a next step, we'll try to fit and evaluate all of those. Make sure to import them here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a next step, we'll fit different classification models and use cross validation to improve our models. We'll look at the average accuracy of these models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ❗ The parameter n_jobs specifies how many cross validations can be ran in parallel. Make sure to use n_jobs = -1 when doing cross validation.  This will allow you to run as many jobs simultanously as possible. Training these models can take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_pair = [(\"logistic_regression\", LogisticRegressionCV()), (\"random_forest\", RandomForestClassifier()), (\"gradient boosting\", HistGradientBoostingClassifier()), (\"decision tree\", DecisionTreeClassifier()) ]\n",
    "pipes = []\n",
    "for pair in model_name_pair:\n",
    "    name, model = pair\n",
    "    print(f\"STARTING {name}\")\n",
    "    pipe = make_pipeline(preprocessor, model)\n",
    "    pipes.append(pipe)\n",
    "    results_acc = cross_val_score(pipe, X_train, y_train, cv=4, scoring=\"accuracy\", n_jobs=-1) \n",
    "    print(\"-\"*20)\n",
    "    print(f\"The accuracy on the training set is {np.mean(results_acc)}\\n\")\n",
    "    print(f\"The auc on the training set is {np.mean(results_roc)} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat this process, but now with roc_auc as scoring metric. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ❓ Motivate which model is the best and use it on the final part of the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the final model. Chose the best mode from 'pipes' above, pipes[0] being the logistic regression model and so on.\n",
    "rf_pipe = pipes[]\n",
    "rf_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make your predictions\n",
    "y_pred = rf_pipe.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the final accuracy\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's add a visualisation of the confusion matrix and roc curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# 1. Get predicted probabilities for the positive class\n",
    "y_prob = rf_pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 2. Compute FPR, TPR and thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "# 3. Compute AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# 4. Plot ROC curve\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--', label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAMLvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
