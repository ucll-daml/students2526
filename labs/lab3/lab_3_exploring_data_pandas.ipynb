{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images\\Logo_UCLL_ENG_RGB.png\" style=\"background-color:white;\" />\n",
    "\n",
    "# Data Analytics & Machine learning\n",
    "\n",
    "Lecturers: Aimée Lynn Backiel, Kenric Borgelioen, Sofie Torfs, Lies Bollens\n",
    "\n",
    "Academic year 2025-2026\n",
    "\n",
    "## Lab 3: Data analytics with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap of last lab(s)\n",
    "\n",
    "#### Lab 1\n",
    "\n",
    "1. We ensured we had a valid Python installation.\n",
    "2. We learnt what a virtual environment is:\n",
    "   * Isolated Python executable and packages.\n",
    "   * We created a virtual environment.\n",
    "3. Absolute path vs relative path recap.\n",
    "4. Recap of data structures in Python\n",
    "\n",
    "#### Lab 2\n",
    "1. Installed Pandas\n",
    "2. Learnt how to read data\n",
    "3. Learnt how to calculate mean, mode, median etc.\n",
    "4. Basic exploration of the 4 variables\n",
    "5. Bivariate exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ada Turing Travelogue, or as everyone calls her, Ada just started working part time at her parents travel agency. She has a keen understanding and interest of everything related to applied computer science ranging from server & system management to full stack software development. Through database foundations she already understands how to query data and programming 1 and 2 covered the essentials about the Python programming language. Recently she has just decided to start learning about data analytics & machine learning as well.\n",
    "\n",
    "She uses her skills to connect to the travel agency's database where she finds many, normalized, tables. Ada recalls what she learnt in database foundations and performs all the correct joins. Afterwards she saves the data in the `data/` folder.\n",
    "\n",
    "\n",
    "She finds the following dataset:\n",
    "\n",
    "| Column Name          | Description                                                                                       |\n",
    "| -------------------- | ------------------------------------------------------------------------------------------------- |\n",
    "| SalesID              | Unique identifier for each sale.                                                                  |\n",
    "| Age                  | Age of the traveler.                                                                              |\n",
    "| Country              | Country of origin of the traveler.                                                                |\n",
    "| Membership_Status    | Membership level of the traveler in the booking system; could be 'standard', 'silver', or 'gold'. |\n",
    "| Previous_Purchases   | Number of previous bookings made by the traveler.                                                 |\n",
    "| Destination          | Travel destination chosen by the traveler.                                                        |\n",
    "| Stay_length          | Duration of stay at the destination.                                                              |\n",
    "| Guests               | Number of guests traveling (including the primary traveler).                                             |\n",
    "| Travel_month         | Month in which the travel is scheduled.                                                           |\n",
    "| Months_before_travel | Number of months prior to travel that the booking was made.                                       |\n",
    "| Earlybird_discount   | Boolean flag indicating whether the traveler received an early bird discount.                     |\n",
    "| Package_Type         | Type of travel package chosen by the traveler.                                                    |\n",
    "| Cost                 | Calculated cost of the travel package.                                                            |\n",
    "| Margin | The cost (for the traveler) - what the travel agency pays. |\n",
    " | Additional_Services_Cost| The amount of additional services (towels, car rentals, room service, ...) that was bought during the trip. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helping Ada explore the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goal for the remainder of this lab is to explore the data. We will specifically take five columns:\n",
    "\n",
    "* cost\n",
    "* age\n",
    "* stay_length\n",
    "* destination\n",
    "* country\n",
    "\n",
    "Our goal is to find interesting relationships between them.\n",
    "\n",
    "As was covered in the book and lecture there are two main data types in analytics: categorical and numerical data. This is a crucial first step in your analysis because it determines what methods make sense on your data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The goal is primarily to find out what influences the cost of the stay.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Recap from last week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading and exploring data: univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # by convention\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset = pd.read_csv(\"data/lab_3_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a very short refresher of last week's lab. One of the first things you typically do with a dataset is print out the first few rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing the columns is equally trivial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also make subsets like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"country\", \"stay_length\", \"age\", \"cost\", \"destination\"]\n",
    "travel_dataset_subset = travel_dataset[columns]\n",
    "travel_dataset_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ❓ Summarize all the numerical variables with one line of code. Write down everything you notice about the variable cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR OBSERVATIONS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ❓ Summarize one of the categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUR OBSERVATION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Data exploration - bivariate\n",
    "\n",
    "\n",
    "Now we will look at pairs of variables, to see if we find any interesting relations between two variables. This analysis takes multiple steps.\n",
    "1) First, you decide which two variables might be interesting to look at together\n",
    "2) Second, you have to decide upon a technique for analysis. This technique will differ depending on the type of variable. The different combinations are: two numerical variables, two categorical variables and one categorical and one numerical variable. \n",
    "3) Depending on the type of variables, you can carry out different analysis. We will explore this below, with one example for each type, to give you an idea of what different analysis looks like for different types of variables. \n",
    "\n",
    "Later, when you encounter two other variables you want to analyse, you can use these examples as a blueprint to start carrying out the correct analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ❓ Which variables do you think are interesting to take a look at together?  Write a short motivation on why you would like to look at them and why you chose this technique to analyse this. Then carry out the proper analysis. Choose at least three different combinations: two categorical, two numerical, and one categorical and a numerical variable. Don't lose sight of what we are trying to figure out: what influences the cost of the stay. End your answer with what you observe from your analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) Two numerical variables:\n",
    "- Why do you look at them? \n",
    "- What technique do you use and why? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR MOTIVATION HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR OBSERVATIONS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) One numerical variable and one categorical variable: \n",
    "\n",
    "- Why do you look at them? \n",
    "- What technique do you use and why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR MOTIVATION HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR OBSERVATIONS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3 ) Two categorical variables:\n",
    "\n",
    "This analysis will follow the same structure as before. Now, it's up to you to create your own markdown and code cells. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ❓ Extra: I'd like to study age and cost using the groupby method. Is that a good idea? Explain why or why not. If not, do you see a way to make it work?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR EXPLANATION HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ❓ If you have not done so before, analyze cost per destination. Do you notice any abnormal results?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR OBSERVATIONS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ❓ How would you deal with this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3:  Subsetting and cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ada gets confirmation from her contacts that the data has some issues. The booking system broke down and produced large negative values. Additionally, the currency converter for Tokyo is giving incorrect results.\n",
    "\n",
    "We will help her rectify these mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Removing data: boolean indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally it's a good idea to not alter your original dataset but filter it in a copy. The way Pandas does this is by filtering with a boolean mask. We will demonstrate step by step how to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://numpy.org/doc/stable/_images/broadcasting_1.png\" style=\"background-color:white;\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we want gone are the rows where the cost equals `-1000000.00`. We can check for each row if that's the case. \n",
    "\n",
    "Pandas uses a technique called \"broadcasting\" where if you try to do operations between values of different shapes Pandas will try to expand one to make them match.\n",
    "\n",
    "This means you don't need to explicitly turn the value into an array of the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_errors = travel_dataset[\"cost\"] != -1000000.00\n",
    "non_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Check how many non_errors we have in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Is explicitly checking if the cost does not equal -1000000.00 the best way to filter out wrong cost values? Adapt the checking for non_errors to a more logical constraint. See if we still have the same number of errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas allows you to give a boolean array as an index to filter out rows. The rows where the boolean array (also known as a mask) is `True` are kept. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset[non_errors] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also combine all of the above in one line, to directly filter out all the values with a faulty cost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset[#YOUR CONDITION HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ❓Create a new dataset called `_dataset_cleaned` , which contains only the rows with a non faulty value. Make a copy of the original dataset, such that we do not accidentally alter values in the original dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ❓ Make a mask for the people that traveled to Tokyo. Call the variable `tokyo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Updating rows the right way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now grab the rows where the destination is Tokyo as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dataset_cleaned[tokyo]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a filtered dataset of all people that traveled to Tokyo, with the faulty values already removed.\n",
    "We can take a look at the cost column as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dataset_cleaned[tokyo][\"cost\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the rows we can convert the currency by dividing by 158, to get the correct price. \n",
    "You will likely try to do this in the following way:\n",
    "\n",
    "`_dataset_cleaned[tokyo][\"cost\"] /= 158`\n",
    "\n",
    "You can try it out below and look at the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dataset_cleaned[tokyo][\"cost\"] /= 158"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us the same error as we encountered in the previous session. The way we can get around is is by using `data.loc`.\n",
    "\n",
    "When we read the error message, it tells us two things: \n",
    "1) The abovementioned code currently still works in certain cases, but in the future it will not work anymore. \n",
    "\n",
    "*This is a sure sign that we should not use this line of code anymore. If we would, in the future, it might suddenly break and not function anymore. Right now, we know where we are coding and can easily update this line of code. But, in the future, we might have a whole project with 1000s of lines of code. If you then have to look for where exactly the error occurs, you will end up spending a long time doing something not very fun. Think about future you.*\n",
    "\n",
    "2) to use  `df.loc[row_indexer, \"col\"] = values` instead, since this will ensure we **keep on updating the original dataframe**. \n",
    "\n",
    "\n",
    "\n",
    "`df.loc` can be quite confusing. It is an object you can slice by using square brackets `[]`. The first element is the **index**. This is typically the column on the far left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dataset_cleaned.index # Each dataframe has an index, which is shown on the left. It typically starts at 0 and goes to the number of rows - 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokyo.index # Each series has an index too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dataset_cleaned.loc[tokyo] # Loc filters the dataset where tokyo is true  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dataset_cleaned.loc[tokyo, \"cost\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a good habit to make a copy before you change your data. If you don't do this and make a mistake you need to rerun your entire script. For a small dataset like this it's not a big problem, but as you scale it can become a bottleneck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset = _dataset_cleaned.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cleaned_dataset.loc[tokyo, \"cost\"] /= 158"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dataset_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also give columns or a list of columns to `.loc`. In this case only the rows we ask for will be returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dataset_cleaned.loc[tokyo, \"cost\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a good habit to make a copy before you change your data. If you don't do this and make a mistake you need to rerun your entire script. For a small dataset like this it's not a big problem, but as you scale it can become a bottleneck.\n",
    "\n",
    "\n",
    "##### ❓ create a new copy of the dataset, called `cleaned_dataset`. Use the df.loc function to divide the cost of the trips to Tokyo by 158. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ❓We will briefly look at the impact of what we did on our analysis of cost by destination. What effect did our corrections have on the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR OBSERVATIONS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ❓Compare the correlation between age, cost and stay length before and after data cleaning. What differences do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR OBSERVATION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### ❓ How do we interpret these correlations? Why do you think the correlations changed so much? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR EXPLANATION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra food for thought: \n",
    "- correlation only gives a measure of linear relationships. Low correlations don't always mean an absence of a relationship, it could be there but just non-linear.\n",
    "- a correlation measures the fact that there is **a** linear relationship. However, how exactly to interpret these numbers is not necessarily straightforward. \n",
    "\n",
    "\n",
    "How do we interpret our correlation value of 0.75?\n",
    "\n",
    "**What correlation does NOT mean**\n",
    "> If variable A increases with 1 unit variable B increases with 0.75 units.\n",
    "\n",
    "**Why is this not the interpretation?** \n",
    "\n",
    "The (sample) correlation $r_{X,Y}$ is given as:\n",
    "\n",
    "$$\n",
    "r_{x,y} = \\frac{cov(x,y)}{(n-1)s_{x}s_{y}} = \\frac{\\sum_{i=1}^{n}{(x_{i} - \\bar{x})(y_{i} - \\bar{y})}}{(n-1)s_{x}s_{y}}\n",
    "$$\n",
    "\n",
    "We have some notation to unpack here.\n",
    "\n",
    "We have two variables $x$ and $y$. These each have a mean $\\bar{x}$ and $\\bar{y}$ pronounced as x bar and y bar respectively, $s_{x}$ and $s_{y}$ are respectively the standard deviations of x and y.\n",
    "\n",
    "The first equality shows us that the correlation $r_{x, y}$ is a normalized version of something called the covariance (cov). The scaling is achieved by dividing by a factor related to the product of the standard deviations of the two variables. This is what ensures that $r_{x,y} \\in [-1, 1]$. \n",
    "\n",
    "Thee covariance expresses the joint variability of two variables. A covariance of 8 means that if variable x increased by 1 the other variable increases by an amount that is dependent on the units and scale of both variables; it doesn't specify a fixed number of units either.\n",
    "\n",
    "Thus, the correct interpretation of a correlation coefficient is: \n",
    "\n",
    "> A correlation coefficient, measures the strength and direction of a linear relationship between two variables, but not the slope of that relationship.\n",
    "\n",
    "Finally, to know how much one variable varies in function of the other we can look at the regression slope:\n",
    "\n",
    "$$\n",
    "\\beta_{y} = r_{x,y}\\frac{s_{x}}{s_{y}}\n",
    "$$\n",
    "\n",
    "The slope of the regression has a deep connection with the correlation. It's the correlation weighted by the proportion of the standard deviations. Logically, if $s_{x} = s_{y}$ the interpretation given last lecture holds. Generally that is not the case, so those that made this remark last lecture were correct. The equation above shows that it is trivial to recover the slope from the correlation.\n",
    "\n",
    "It is important to remember that correlations and the slope of a regression are expressing linear relationships. As discussed last lecture Anscombe's quartet consists of four datasets that have nearly identical simple descriptive statistics, yet have very different distributions and appear very different when graphed. **This highlights the importance of visualizing data and not relying solely on statistical metrics.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<center>\n",
    "Anscomnbe's quarter: four datasets with an equal correlation.\n",
    "<br>\n",
    "<br>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Anscombe%27s_quartet_3.svg/1200px-Anscombe%27s_quartet_3.svg.png\" style=\"width:50%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to plotting with Matplotlib, Seaborn and Plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have helped Ada so far to gain insights into her data by wrangling it into shape and making tables to summarize data. Now, to further enhance our understanding and visualize the patterns, trends, and potential anomalies, we will be plotting the data. \n",
    "\n",
    "Making data visual simplifies complex datasets and also makes it more intuitive for stakeholders to grasp key takeaways. By transitioning from tabular summaries to graphical plots, we can also communicate more effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matplotlib\n",
    "\n",
    "<center>\n",
    "<img src=\"https://matplotlib.org/stable/_images/sphx_glr_logos2_003.png\" style=\"background-color:white\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The name matplotlib comes from matrix plotting library. It's a descendant from the MATLAB programming language. It's by now an older library (2003) that has some quirks, but it is still important to know the basics of Matplotlib since other Python plotting libraries build on top of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to install\n",
    "#%pip install matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # convention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plotting univariate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The table below is a summary of the different types of plots for **numeric data**.\n",
    "\n",
    "| Plot Type          | Description                                           | When to Use                                                      |\n",
    "|--------------------|-------------------------------------------------------|------------------------------------------------------------------|\n",
    "| **Histogram**      | Displays the distribution of a single continuous variable by dividing the data into bins and showing the frequency of observations in each bin. | To visualize the distribution of a variable, especially to identify its central tendency (mean), spread (standard deviation), and skewness (are low or high values more common).  |\n",
    "| **Box Plot (or Whisker Plot)** | Shows the distribution of a variable using quartiles and displays potential outliers. | To get a summary of a variable's distribution in terms of its median, quartiles, and possible outliers. Useful when comparing the distribution across categories. |\n",
    "| **Density Plot (or Kernel Density Plot)** | Provides a smoothed version of a histogram. | To visualize the distribution of a variable in a continuous manner. Particularly useful when comparing the distributions of multiple variables on the same plot. |\n",
    "| **Violin Plot**    | Combines aspects of box plots and density plots.       | To visualize both the distribution and summary statistics of a variable. Especially useful when comparing across different categories. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax for plotting is generally `plt.<plotType>(x, y)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(cleaned_dataset[\"cost\"]); # Matplotlib prints things while plotting, the semicolon an suppress it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A boxplot provides a comprehensive view of a dataset's distribution, offering more detailed insights than typical tables. The central line within the box represents the median, splitting the data into its lower and upper halves. The box itself is framed by two lines: the lower boundary represents the 25th percentile (or Q1), meaning 25% of the data lies below this value, and the upper boundary denotes the 75th percentile (or Q3), indicating that 75% of the data is below this point.\n",
    "\n",
    "The range between Q3 and Q1 is known as the Interquartile Range (IQR). Beyond the box, the plot extends 'whiskers'. Their \"distance\" is calculated as `1.5 * IQR` both above and below the box, providing a range for typical data points. Any data outside these whiskers can be considered possible outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ❓ What can we learn from this boxplot? Try answering the following questions in your response:\n",
    "* is the data symmetrical, or skewed? How did you see this? What does that mean for the cost variable?\n",
    "* is there a large spread in the data or not? How did you see this? What does that mean for the cost variable?\n",
    "* where does most of the data lie? Are there any points that differ significantly from the others?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR OBSERVATIONS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ❓Take a look at the list of possible plots above. Which one would make sense to make when we are just looking at one variable at the time? Figure out the syntax to make this plot and create one for cost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all goes well, you made a histogram in the figure above. The histogram has a parameter called 'bins'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ❓Try setting bins to different values. Can you figure out what it does? Try to find a good value for bins for cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ❓How would you interpret this histogram? Use the same questions as with the boxplot to formulate your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR INTERPRETATION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ❓Now make both of these figures again for age and interpret the results. You can write one conclusion in which you discuss both plots at ones if you prefer. Make sure to describe WHAT you see and WHERE you see it on the plot. (This time, make your own code and markdown boxes again.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For categorical data, categories can often serve as a basis for comparison in other plots, like boxplots. This means you can use a single category to differentiate data within such plots. You can also produce the same type of plot multiple times, once for each category, to analyze patterns within individual categories.\n",
    "\n",
    "\n",
    "| Plot Type     | Description                                          | When to Use                                         |\n",
    "|---------------|------------------------------------------------------|-----------------------------------------------------|\n",
    "| **Count Plot**| Represents the frequency or count of each category.  | To see how often each category appears in the data. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count plots require an additional package, called seaborn. We will learn how to make plots with seaborn in the next lab."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
